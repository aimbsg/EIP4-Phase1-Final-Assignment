{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP4 - Phase 1 - Final Assignment - PersonAttributes.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimbsg/EIP4-Phase1-Final-Assignment/blob/master/EIP4_Phase_1_Final_Assignment_PersonAttributes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "import os\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from keras.backend import sigmoid\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "# remove unwanted columns\n",
        "del df[\"filename\"] \n",
        "#del df[\"image_path\"]\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True, augmentation=None):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        self.augmentation = augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        if self.augmentation is not None:\n",
        "          image = self.augmentation.flow(image, shuffle=False).next()\n",
        "        \n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15, random_state = 1234)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32, augmentation = ImageDataGenerator(rescale=1./255,\n",
        "        #featurewise_center = True,\n",
        "        #featurewise_std_normalization =True,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.4,\n",
        "        #brightness_range=[0.5,1.5],\n",
        "        horizontal_flip = True,\n",
        "        vertical_flip=True,\n",
        "        zca_whitening = True#,\n",
        "        #fill_mode='nearest'))\n",
        "# 0-80 epochs shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True\n",
        "# 80-120 epochs shear_range = 0.1, zoom_range = 0.1, vertical_flip = True\n",
        "# 120-160 epochs shear_range = 0.2, zoom_range = 0.4, vertical_flip = True, zca_whitening = True\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=32, shuffle=False, augmentation=ImageDataGenerator(rescale=1./255))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IFRh2XAgvn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining swish() function\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "  \n",
        "class Swish(Activation):\n",
        "    \n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(Swish, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'swish'\n",
        "\n",
        "def swish(x):\n",
        "    return (K.sigmoid(x) * x)\n",
        "\n",
        "get_custom_objects().update({'swish': Swish(swish)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#backbone = ResNet50(\n",
        "#    weights=None, \n",
        "#    include_top=False, \n",
        "#    input_tensor=Input(shape=(224, 224, 3))\n",
        "#)\n",
        "\n",
        "backbone = InceptionResNetV2(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        "    #,pooling='max'\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "#neck = GlobalAveragePooling2D()(neck)\n",
        "neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(256, activation=\"relu\")(neck) \n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    #neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)    \n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, act_func, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=act_func, name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", \"softmax\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", \"softmax\", build_tower(neck))\n",
        "age = build_head(\"age\", \"swish\", build_tower(neck))\n",
        "weight = build_head(\"weight\", \"relu\", build_tower(neck))\n",
        "bag = build_head(\"bag\", \"sigmoid\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", \"sigmoid\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", \"sigmoid\", build_tower(neck))\n",
        "pose = build_head(\"pose\", \"sigmoid\", build_tower(neck))\n",
        "\n",
        "#model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=Input(shape=(224, 224, 3)), pooling=None, classes=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PavauZeaaa8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxWVxcbi_y6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze backbone\n",
        "for layer in backbone.layers:\n",
        "\tlayer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " losses = {\n",
        " \t\"gender_output\": \"binary_crossentropy\",\n",
        " \t\"image_quality_output\": \"categorical_crossentropy\",\n",
        " \t\"age_output\": \"categorical_crossentropy\",\n",
        " \t\"weight_output\": \"categorical_crossentropy\",\n",
        "   \"bag_output\": \"categorical_crossentropy\",\n",
        "   \"footwear_output\": \"categorical_crossentropy\",\n",
        "   \"pose_output\": \"categorical_crossentropy\",\n",
        "   \"emotion_output\": \"categorical_crossentropy\"\n",
        " }\n",
        "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "sgd = SGD(lr=0.0001, momentum=0.85, nesterov=False)\n",
        "model.compile(\n",
        "    optimizer=sgd,\n",
        "    #optimizer = Adadelta(lr=1.0, rho=0.95),\n",
        "    #optimizer=Adam(lr=lr_schedule(0)),\n",
        "    loss=losses, \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlm55PJvolLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 0.001  # 1e-3 was default till 40 epochs; 1e-4 till 80 epochs; 1e-5 till 160 epochs\n",
        "    if epoch > 80:\n",
        "        lr *= 0.00001\n",
        "    elif epoch > 40:\n",
        "        lr *= 0.0001\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgBSq9I1pKoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'Inc_ResNetModel.{epoch:03d}.h5'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_age_output_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "#callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "callbacks = [checkpoint, lr_scheduler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWDb_aO5QBjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load model\n",
        "\n",
        "model = load_model('/content/gdrive/My Drive/Qual_Assign_Inc_Resnet_model_120epochs.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=1, \n",
        "    epochs=160,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks,\n",
        "    initial_epoch=120\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoEfNvZ9-j5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_results = model.evaluate_generator(valid_gen, verbose=1)\n",
        "dict(zip(model.metrics_names, val_results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LWshFeC6eSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/gdrive/My Drive/Qual_Assign_Inc_Resnet_model_160epochs.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}